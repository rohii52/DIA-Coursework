{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "# Code Implemented by,\n",
    "# Name: Rohith Ganesan\n",
    "# Id: 20553375\n",
    "# Mail: psxrg10@nottingham.ac.uk\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "# goal\n",
    "GOAL = 100\n",
    "\n",
    "# all states, including state 0 and state 100\n",
    "STATES = np.arange(GOAL + 1)\n",
    "\n",
    "# probability of head\n",
    "HEAD_PROB = 0.4\n",
    "\n",
    "def figure_4_3():\n",
    "    # state value\n",
    "    state_value = np.zeros(GOAL + 1)\n",
    "    state_value[GOAL] = 1.0\n",
    "\n",
    "    sweeps_history = []\n",
    "\n",
    "    # value iteration\n",
    "    while True:\n",
    "        old_state_value = state_value.copy()\n",
    "        sweeps_history.append(old_state_value)\n",
    "        \n",
    "        for state in STATES[1:GOAL]:\n",
    "            # get possible actions for current state\n",
    "            actions = np.arange(min(state, GOAL - state) + 1)\n",
    "            action_returns = []\n",
    "            for action in actions:\n",
    "                action_returns.append(\n",
    "                    HEAD_PROB * state_value[state + action] + (1 - HEAD_PROB) * state_value[state - action]\n",
    "                )\n",
    "            new_value = np.max(action_returns)\n",
    "            state_value[state] = new_value\n",
    "        delta = abs(state_value - old_state_value).max()\n",
    "        if delta < 1e-9:\n",
    "            sweeps_history.append(state_value)\n",
    "            break\n",
    "\n",
    "    # compute the optimal policy\n",
    "    policy = np.zeros(GOAL + 1)\n",
    "    for state in STATES[1:GOAL]:\n",
    "        actions = np.arange(min(state, GOAL - state) + 1)\n",
    "        action_returns = []\n",
    "        for action in actions:\n",
    "            action_returns.append(\n",
    "                HEAD_PROB * state_value[state + action] + (1 - HEAD_PROB) * state_value[state - action]\n",
    "            )\n",
    "        # rounding to resemble the figure in the book (Richard S. Sutton, Andrew G Barto - Reinforcement Learning_ An Introduction, 2nd Edition-Bradford Books (2018) ) , see\n",
    "        # https://github.com/ShangtongZhang/reinforcement-learning-an-introduction/issues/83\n",
    "        policy[state] = actions[np.argmax(np.round(action_returns[1:], 5)) + 1]\n",
    "\n",
    "    plt.figure(figsize=(10, 20))\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for sweep, state_value in enumerate(sweeps_history):\n",
    "        plt.plot(state_value, label='sweep {}'.format(sweep))\n",
    "    plt.xlabel('Capital')\n",
    "    plt.ylabel('Value estimates')\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.scatter(STATES, policy)\n",
    "    plt.xlabel('Capital')\n",
    "    plt.ylabel('Final policy (stake)')\n",
    "\n",
    "    plt.savefig('gambler_problem_plot.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    figure_4_3()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAPER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
